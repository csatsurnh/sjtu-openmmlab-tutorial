{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127dd72e-7ed6-4e6b-8864-be0b479ccf2e",
   "metadata": {},
   "source": [
    "# Train Image Classifiers\n",
    "\n",
    "In this notebook we will train an image classifier that classify fruit images, using MMClassificaiton."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22298ae9-0024-4e86-a903-4981053f5424",
   "metadata": {},
   "source": [
    "## Prepare a Dataset\n",
    "\n",
    "We have already prepared a dataset.\n",
    "\n",
    "Credit to Zihao: https://github.com/TommyZihao/MMClassification_Tutorials\n",
    "\n",
    "```\n",
    "!curl -O https://zihao-openmmlab.obs.myhuaweicloud.com/20220716-mmclassification/dataset/fruit30/fruit30_split.zip\n",
    "!unzip -d data fruit30_split.zip\n",
    "```\n",
    "\n",
    "The dataset should be categorized by folders, for MMClassification to read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd9fc5f-d7a7-4bf4-8c43-ab7156e81831",
   "metadata": {},
   "source": [
    "## Prepare a Config and Checkpoint File\n",
    "\n",
    "For speed consideration, we use a lightweight neural network, MobileNetV2.\n",
    "\n",
    "we use mim to download the config file and checkponit file.\n",
    "\n",
    "```\n",
    "!mim download mmcls --config mobilenet-v2_8xb32_in1k --dest .\n",
    "!mv mobilenet-v2_8xb32_in1k.py mobilenet-v2_fruit.py\n",
    "```\n",
    "\n",
    "If you prefer to play with other models, navitage to [MMClassification model zoo](https://mmclassification.readthedocs.io/en/latest/model_zoo.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76ca0906-acf9-4096-878a-7504e0d0622a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing mobilenet-v2_8xb32_in1k...\n",
      "mobilenet_v2_batch256_imagenet_20200708-3b2dc3af.pth exists in C:\\Users\\wangruohui\\Desktop\\sjtu-openmmlab-tutorial\n",
      "Successfully dumped mobilenet-v2_8xb32_in1k.py to C:\\Users\\wangruohui\\Desktop\\sjtu-openmmlab-tutorial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangruohui\\Miniconda3\\envs\\mm\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "!mim download mmcls --config mobilenet-v2_8xb32_in1k --dest .\n",
    "!mv mobilenet-v2_8xb32_in1k.py mobilenet-v2_fruit.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e6ada9-8978-495c-86e2-a965799ddbb9",
   "metadata": {},
   "source": [
    "## Modify the Config File\n",
    "\n",
    "1. Remove some intermediate item for clean: `dataset_type`, `img_norm_cfg`, `train_pipeline`, `test_pipeline`\n",
    "1. Modify model\n",
    "    1. number of class: from 1000 to 30\n",
    "    2. pretrain weights: from None to the downloaded checkpoint file, as we finetune the model instead of training from scratch\n",
    "1. Data: for train/val/test \n",
    "    1. `type`: `ImageNet` -> `CustomDataset`\n",
    "    2. `prefix`, which is the root path to images: modify to `\"data/fruit30_split/train\"` or `\"data/fruit30_split/val\"`\n",
    "    3. `ann_file`, use folder name as class name: modify to `None`\n",
    "1. Runner and Optimizer\n",
    "    1. number of training epochs: `runner.max_epochs`\n",
    "    1. learning rates: `optimizer.lr`, usually divided by 8 due to linear scaling rules.\n",
    "1. Misc\n",
    "    1. Decrease `log_confg.interval` for small computation power\n",
    "    1. Increate `checkpoint_config.interval` to avoid saving too many checkpoint, to same time and disk space\n",
    "1. Further parameter tuning you may try\n",
    "    1. learning rates: Decrease `optimizer.lr` for finetuning \n",
    "    1. configure learning scheduler to decrease learning when loss saturates. Moreover, by setting `by_epoch=False`, we decrease learning rate by iteration instead of by epoches.\n",
    "    1. Monitor loss decrease and re-tune\n",
    "    1. More available lr_schedulers are available in [mmcv](https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/lr_updater.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8071497-dd81-4121-b2b0-91df11d41734",
   "metadata": {},
   "source": [
    "## Launch Training\n",
    "\n",
    "In command line \n",
    "\n",
    "```\n",
    "mim train mmcls mobilenet-v2_fruit.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da09fe8-4d5c-43d5-9456-0e7bcf8e740c",
   "metadata": {},
   "source": [
    "## Understand Logs\n",
    "\n",
    "\n",
    "The log is long but mainly contains the following parts:\n",
    "\n",
    "1. Toolbox information\n",
    "2. Dumped Config files\n",
    "3. Model Initialization Logs\n",
    "    1. Check `mmcls - INFO - load checkpoint from local path: mobilenet_v2_batch256_imagenet_20200708-3b2dc3af.pth`, which means pretrained weights are loaded correctly.\n",
    "4. Information on Hooks: we don't configure this explicitly in this tutorial, so ignore that\n",
    "5. Training progress\n",
    "    1. Training logs: including current learning, training loss, time consumption, memory occupation\n",
    "    2. Valiation logs: Accuracy on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d437f5a-07a0-43ca-b87d-6502c51050b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
